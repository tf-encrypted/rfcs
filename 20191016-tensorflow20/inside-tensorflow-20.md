
# Inside TensorFlow 2.0

From [here](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/eager/function.py#L2224-L2227):

> Executing a graph generated by `defun` respects device annotations (i.e., all `with tf.device` directives present in a Python function will also be present in its corresponding graph), but it is not yet possible to execute the generated graphs across multiple machines.

From [here](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/eager/function.py#L2289-L2296):

> When using `defun`, there are subtleties regarding inputs, Python control flow, and variable creation that one should be aware of. For concreteness, let `f` be a Python function that returns zero or more `tf.Tensor` objects and let `F = defun(f)`. `F` builds a graph for each unique input signature it sees, Python control flow is baked into graphs, and operations related to variable initialization are automatically lifted out of the graphs that `F` generates and placed in the eager context if executing eagerly or into an outer graph otherwise.

From [here](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/eager/function.py#L2474-L2486):

> Finally, because each input signature is bound to a unique graph, if your Python function constructs `tf.Variable` objects, then each graph constructed for that Python function will reference a unique set of variables. To circumvent this problem, we recommend against compiling Python functions that create `tf.Variable` objects. Instead, Python functions should either lexically close over `tf.Variable` objects or accept them as arguments, preferably encapsulated in an object-oriented container. If you must create variables inside your Python function and you want each graph generated for it to reference the same set of variables, add logic to your Python function that ensures that variables are only created the first time it is called and are reused for every subsequent invocation; note that this is precisely what `tf.keras.layers.Layer` objects do, so we recommend using them to represent variable-bearing computations whenever possible.

`func_graph_from_py_func` is where the [defun magic](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/framework/func_graph.py#L915) happens.

## Eager mode


Virtual devices can be simulated for local execution using the following snippet:

```python
tf.config.set_soft_device_placement(False)

virtual_devices = [
    tf_config.experimental.VirtualDeviceConfiguration()
    for _ in player_names
]

tf_config.experimental.set_virtual_device_configuration(
    tf_config.experimental.list_physical_devices('CPU')[0],
    virtual_devices)
```

or for remote execution:

```python
tf.config.set_soft_device_placement(False)

cluster = tf.train.ClusterSpec({self._job_name: self.hosts})

tf.config.experimental_connect_to_cluster(cluster)
```

In either case, TensorFlow will take care of remotely executing 


## `tf.function`

To get graph def from function:

graph_def = f.get_concrete_function().graph.as_graph_def()

## Variables

When a function is decorated with tf.function decorator the function is automatically traced and can end up being called more than once. For this reason, variables must be proven not be initialized more than once. TensorFlow documentation recommends that you either create the variable outside of the function or wrap the variable in a class which can store the initialization of the Variable. Following example taken from here.

Create variable outside of function:

```python
v = tf.Variable(1.0)

@tf.function
def f(x):
  return v.assign_add(x)
```

Wrap variable in a class:

```python
class C: pass
obj = C(); obj.v = None

@tf.function
def g(x):
  if obj.v is None:
    obj.v = tf.Variable(1.0)
  return obj.v.assign_add(x)
```

These same principles can be applied when creating Keras models or optimizers inside of a `tf.function`.

### New Variable subclasses

There are several new [variable](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/ops/variables.py) types and a new notions

- [VariableSynchronization](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/ops/variables.py#L71).

- [VariableAggregation](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/ops/variables.py#L93).

- [VariableMetaclass](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/ops/variables.py#L177) *to allow construction of tf.Variable to be overridden*.

- [AbstractVariable](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/ops/variables.py#L3389) used e.g. by [DistributedVariable](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/distribute/values.py#L597).

## Eager Tensors

Store in (remote) memory.

- [EagerTensor](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/framework/ops.py#L1121) and [_EagerTensorBase](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/framework/ops.py#L855) with [_backing_device](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/framework/ops.py#L937-L945).
